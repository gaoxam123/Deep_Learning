{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(x_train, y_train, x_test, y_test, y_preds=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(x_train, y_train, c='b', s=4, label='training_data')\n",
    "    plt.scatter(x_test, y_test, c='g', s=4, label='test_data')\n",
    "    if y_preds is not None:\n",
    "        plt.scatter(x_test, y_preds, c='r', s=4, label='predictions')\n",
    "\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([-2.3284], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2432], requires_grad=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LR()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions with model\n",
    "x_test = torch.tensor(2)\n",
    "with torch.inference_mode():\n",
    "    y_preds = model(x_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_preds = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "OrderedDict([('weights', tensor([-2.2271])), ('bias', tensor([-0.1419]))])\n",
      "epoch: 1\n",
      "OrderedDict([('weights', tensor([-2.2261])), ('bias', tensor([-0.1409]))])\n",
      "epoch: 2\n",
      "OrderedDict([('weights', tensor([-2.2251])), ('bias', tensor([-0.1399]))])\n",
      "epoch: 3\n",
      "OrderedDict([('weights', tensor([-2.2241])), ('bias', tensor([-0.1389]))])\n",
      "epoch: 4\n",
      "OrderedDict([('weights', tensor([-2.2231])), ('bias', tensor([-0.1379]))])\n",
      "epoch: 5\n",
      "OrderedDict([('weights', tensor([-2.2221])), ('bias', tensor([-0.1369]))])\n",
      "epoch: 6\n",
      "OrderedDict([('weights', tensor([-2.2212])), ('bias', tensor([-0.1359]))])\n",
      "epoch: 7\n",
      "OrderedDict([('weights', tensor([-2.2202])), ('bias', tensor([-0.1350]))])\n",
      "epoch: 8\n",
      "OrderedDict([('weights', tensor([-2.2192])), ('bias', tensor([-0.1340]))])\n",
      "epoch: 9\n",
      "OrderedDict([('weights', tensor([-2.2182])), ('bias', tensor([-0.1330]))])\n",
      "epoch: 10\n",
      "OrderedDict([('weights', tensor([-2.2172])), ('bias', tensor([-0.1320]))])\n",
      "epoch: 11\n",
      "OrderedDict([('weights', tensor([-2.2162])), ('bias', tensor([-0.1310]))])\n",
      "epoch: 12\n",
      "OrderedDict([('weights', tensor([-2.2153])), ('bias', tensor([-0.1301]))])\n",
      "epoch: 13\n",
      "OrderedDict([('weights', tensor([-2.2143])), ('bias', tensor([-0.1291]))])\n",
      "epoch: 14\n",
      "OrderedDict([('weights', tensor([-2.2133])), ('bias', tensor([-0.1281]))])\n",
      "epoch: 15\n",
      "OrderedDict([('weights', tensor([-2.2123])), ('bias', tensor([-0.1271]))])\n",
      "epoch: 16\n",
      "OrderedDict([('weights', tensor([-2.2113])), ('bias', tensor([-0.1261]))])\n",
      "epoch: 17\n",
      "OrderedDict([('weights', tensor([-2.2103])), ('bias', tensor([-0.1251]))])\n",
      "epoch: 18\n",
      "OrderedDict([('weights', tensor([-2.2094])), ('bias', tensor([-0.1242]))])\n",
      "epoch: 19\n",
      "OrderedDict([('weights', tensor([-2.2084])), ('bias', tensor([-0.1232]))])\n",
      "epoch: 20\n",
      "OrderedDict([('weights', tensor([-2.2074])), ('bias', tensor([-0.1222]))])\n",
      "epoch: 21\n",
      "OrderedDict([('weights', tensor([-2.2064])), ('bias', tensor([-0.1212]))])\n",
      "epoch: 22\n",
      "OrderedDict([('weights', tensor([-2.2054])), ('bias', tensor([-0.1202]))])\n",
      "epoch: 23\n",
      "OrderedDict([('weights', tensor([-2.2045])), ('bias', tensor([-0.1193]))])\n",
      "epoch: 24\n",
      "OrderedDict([('weights', tensor([-2.2035])), ('bias', tensor([-0.1183]))])\n",
      "epoch: 25\n",
      "OrderedDict([('weights', tensor([-2.2025])), ('bias', tensor([-0.1173]))])\n",
      "epoch: 26\n",
      "OrderedDict([('weights', tensor([-2.2015])), ('bias', tensor([-0.1163]))])\n",
      "epoch: 27\n",
      "OrderedDict([('weights', tensor([-2.2005])), ('bias', tensor([-0.1153]))])\n",
      "epoch: 28\n",
      "OrderedDict([('weights', tensor([-2.1996])), ('bias', tensor([-0.1144]))])\n",
      "epoch: 29\n",
      "OrderedDict([('weights', tensor([-2.1986])), ('bias', tensor([-0.1134]))])\n",
      "epoch: 30\n",
      "OrderedDict([('weights', tensor([-2.1976])), ('bias', tensor([-0.1124]))])\n",
      "epoch: 31\n",
      "OrderedDict([('weights', tensor([-2.1966])), ('bias', tensor([-0.1114]))])\n",
      "epoch: 32\n",
      "OrderedDict([('weights', tensor([-2.1956])), ('bias', tensor([-0.1104]))])\n",
      "epoch: 33\n",
      "OrderedDict([('weights', tensor([-2.1947])), ('bias', tensor([-0.1095]))])\n",
      "epoch: 34\n",
      "OrderedDict([('weights', tensor([-2.1937])), ('bias', tensor([-0.1085]))])\n",
      "epoch: 35\n",
      "OrderedDict([('weights', tensor([-2.1927])), ('bias', tensor([-0.1075]))])\n",
      "epoch: 36\n",
      "OrderedDict([('weights', tensor([-2.1917])), ('bias', tensor([-0.1065]))])\n",
      "epoch: 37\n",
      "OrderedDict([('weights', tensor([-2.1907])), ('bias', tensor([-0.1056]))])\n",
      "epoch: 38\n",
      "OrderedDict([('weights', tensor([-2.1898])), ('bias', tensor([-0.1046]))])\n",
      "epoch: 39\n",
      "OrderedDict([('weights', tensor([-2.1888])), ('bias', tensor([-0.1036]))])\n",
      "epoch: 40\n",
      "OrderedDict([('weights', tensor([-2.1878])), ('bias', tensor([-0.1026]))])\n",
      "epoch: 41\n",
      "OrderedDict([('weights', tensor([-2.1868])), ('bias', tensor([-0.1017]))])\n",
      "epoch: 42\n",
      "OrderedDict([('weights', tensor([-2.1859])), ('bias', tensor([-0.1007]))])\n",
      "epoch: 43\n",
      "OrderedDict([('weights', tensor([-2.1849])), ('bias', tensor([-0.0997]))])\n",
      "epoch: 44\n",
      "OrderedDict([('weights', tensor([-2.1839])), ('bias', tensor([-0.0987]))])\n",
      "epoch: 45\n",
      "OrderedDict([('weights', tensor([-2.1829])), ('bias', tensor([-0.0977]))])\n",
      "epoch: 46\n",
      "OrderedDict([('weights', tensor([-2.1820])), ('bias', tensor([-0.0968]))])\n",
      "epoch: 47\n",
      "OrderedDict([('weights', tensor([-2.1810])), ('bias', tensor([-0.0958]))])\n",
      "epoch: 48\n",
      "OrderedDict([('weights', tensor([-2.1800])), ('bias', tensor([-0.0948]))])\n",
      "epoch: 49\n",
      "OrderedDict([('weights', tensor([-2.1790])), ('bias', tensor([-0.0938]))])\n",
      "epoch: 50\n",
      "OrderedDict([('weights', tensor([-2.1780])), ('bias', tensor([-0.0929]))])\n",
      "epoch: 51\n",
      "OrderedDict([('weights', tensor([-2.1771])), ('bias', tensor([-0.0919]))])\n",
      "epoch: 52\n",
      "OrderedDict([('weights', tensor([-2.1761])), ('bias', tensor([-0.0909]))])\n",
      "epoch: 53\n",
      "OrderedDict([('weights', tensor([-2.1751])), ('bias', tensor([-0.0899]))])\n",
      "epoch: 54\n",
      "OrderedDict([('weights', tensor([-2.1741])), ('bias', tensor([-0.0890]))])\n",
      "epoch: 55\n",
      "OrderedDict([('weights', tensor([-2.1732])), ('bias', tensor([-0.0880]))])\n",
      "epoch: 56\n",
      "OrderedDict([('weights', tensor([-2.1722])), ('bias', tensor([-0.0870]))])\n",
      "epoch: 57\n",
      "OrderedDict([('weights', tensor([-2.1712])), ('bias', tensor([-0.0860]))])\n",
      "epoch: 58\n",
      "OrderedDict([('weights', tensor([-2.1702])), ('bias', tensor([-0.0851]))])\n",
      "epoch: 59\n",
      "OrderedDict([('weights', tensor([-2.1693])), ('bias', tensor([-0.0841]))])\n",
      "epoch: 60\n",
      "OrderedDict([('weights', tensor([-2.1683])), ('bias', tensor([-0.0831]))])\n",
      "epoch: 61\n",
      "OrderedDict([('weights', tensor([-2.1673])), ('bias', tensor([-0.0822]))])\n",
      "epoch: 62\n",
      "OrderedDict([('weights', tensor([-2.1663])), ('bias', tensor([-0.0812]))])\n",
      "epoch: 63\n",
      "OrderedDict([('weights', tensor([-2.1654])), ('bias', tensor([-0.0802]))])\n",
      "epoch: 64\n",
      "OrderedDict([('weights', tensor([-2.1644])), ('bias', tensor([-0.0792]))])\n",
      "epoch: 65\n",
      "OrderedDict([('weights', tensor([-2.1634])), ('bias', tensor([-0.0783]))])\n",
      "epoch: 66\n",
      "OrderedDict([('weights', tensor([-2.1625])), ('bias', tensor([-0.0773]))])\n",
      "epoch: 67\n",
      "OrderedDict([('weights', tensor([-2.1615])), ('bias', tensor([-0.0763]))])\n",
      "epoch: 68\n",
      "OrderedDict([('weights', tensor([-2.1605])), ('bias', tensor([-0.0754]))])\n",
      "epoch: 69\n",
      "OrderedDict([('weights', tensor([-2.1595])), ('bias', tensor([-0.0744]))])\n",
      "epoch: 70\n",
      "OrderedDict([('weights', tensor([-2.1586])), ('bias', tensor([-0.0734]))])\n",
      "epoch: 71\n",
      "OrderedDict([('weights', tensor([-2.1576])), ('bias', tensor([-0.0724]))])\n",
      "epoch: 72\n",
      "OrderedDict([('weights', tensor([-2.1566])), ('bias', tensor([-0.0715]))])\n",
      "epoch: 73\n",
      "OrderedDict([('weights', tensor([-2.1556])), ('bias', tensor([-0.0705]))])\n",
      "epoch: 74\n",
      "OrderedDict([('weights', tensor([-2.1547])), ('bias', tensor([-0.0695]))])\n",
      "epoch: 75\n",
      "OrderedDict([('weights', tensor([-2.1537])), ('bias', tensor([-0.0686]))])\n",
      "epoch: 76\n",
      "OrderedDict([('weights', tensor([-2.1527])), ('bias', tensor([-0.0676]))])\n",
      "epoch: 77\n",
      "OrderedDict([('weights', tensor([-2.1518])), ('bias', tensor([-0.0666]))])\n",
      "epoch: 78\n",
      "OrderedDict([('weights', tensor([-2.1508])), ('bias', tensor([-0.0656]))])\n",
      "epoch: 79\n",
      "OrderedDict([('weights', tensor([-2.1498])), ('bias', tensor([-0.0647]))])\n",
      "epoch: 80\n",
      "OrderedDict([('weights', tensor([-2.1488])), ('bias', tensor([-0.0637]))])\n",
      "epoch: 81\n",
      "OrderedDict([('weights', tensor([-2.1479])), ('bias', tensor([-0.0627]))])\n",
      "epoch: 82\n",
      "OrderedDict([('weights', tensor([-2.1469])), ('bias', tensor([-0.0618]))])\n",
      "epoch: 83\n",
      "OrderedDict([('weights', tensor([-2.1459])), ('bias', tensor([-0.0608]))])\n",
      "epoch: 84\n",
      "OrderedDict([('weights', tensor([-2.1450])), ('bias', tensor([-0.0598]))])\n",
      "epoch: 85\n",
      "OrderedDict([('weights', tensor([-2.1440])), ('bias', tensor([-0.0589]))])\n",
      "epoch: 86\n",
      "OrderedDict([('weights', tensor([-2.1430])), ('bias', tensor([-0.0579]))])\n",
      "epoch: 87\n",
      "OrderedDict([('weights', tensor([-2.1421])), ('bias', tensor([-0.0569]))])\n",
      "epoch: 88\n",
      "OrderedDict([('weights', tensor([-2.1411])), ('bias', tensor([-0.0560]))])\n",
      "epoch: 89\n",
      "OrderedDict([('weights', tensor([-2.1401])), ('bias', tensor([-0.0550]))])\n",
      "epoch: 90\n",
      "OrderedDict([('weights', tensor([-2.1391])), ('bias', tensor([-0.0540]))])\n",
      "epoch: 91\n",
      "OrderedDict([('weights', tensor([-2.1382])), ('bias', tensor([-0.0531]))])\n",
      "epoch: 92\n",
      "OrderedDict([('weights', tensor([-2.1372])), ('bias', tensor([-0.0521]))])\n",
      "epoch: 93\n",
      "OrderedDict([('weights', tensor([-2.1362])), ('bias', tensor([-0.0511]))])\n",
      "epoch: 94\n",
      "OrderedDict([('weights', tensor([-2.1353])), ('bias', tensor([-0.0502]))])\n",
      "epoch: 95\n",
      "OrderedDict([('weights', tensor([-2.1343])), ('bias', tensor([-0.0492]))])\n",
      "epoch: 96\n",
      "OrderedDict([('weights', tensor([-2.1333])), ('bias', tensor([-0.0482]))])\n",
      "epoch: 97\n",
      "OrderedDict([('weights', tensor([-2.1324])), ('bias', tensor([-0.0473]))])\n",
      "epoch: 98\n",
      "OrderedDict([('weights', tensor([-2.1314])), ('bias', tensor([-0.0463]))])\n",
      "epoch: 99\n",
      "OrderedDict([('weights', tensor([-2.1304])), ('bias', tensor([-0.0453]))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minht\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# building a training loop\n",
    "x_train = torch.tensor([1, 2, 3, 4, 5, 6], dtype=torch.float32)\n",
    "y_train = torch.tensor([1, 2, 3, 4, 5, 6], dtype=torch.float32)\n",
    "y_test = torch.tensor(2)\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_preds = model(x_train)\n",
    "    loss = loss_fn(y_preds, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_preds = model(x_test)\n",
    "        test_loss = loss_fn(y_preds, y_test)\n",
    "\n",
    "    print(f'epoch: {epoch}')\n",
    "    print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# model_path = Path('models')\n",
    "# model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# model_name = 'fuck.pth'\n",
    "# model_save_path = model_path/model_name\n",
    "\n",
    "# torch.save(obj=model.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = LR()\n",
    "\n",
    "# loaded_model.load_state_dict(torch.load(f=model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
